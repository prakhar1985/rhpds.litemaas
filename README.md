# LiteMaaS Ansible Collection

Deploy LiteMaaS (Models as a Service) on OpenShift in 3 minutes.

## What is LiteMaaS?

LiteMaaS provides an admin-managed AI model serving platform with:
- **LiteLLM Gateway**: Unified API for multiple AI model providers
- **Admin Interface**: Manage models, create user keys, track usage
- **OpenShift AI Integration**: Host local models (Granite, Llama, Mistral)
- **Virtual Key Management**: Control user access and budgets
- **Cost Tracking**: Monitor spending across all models

## Quick Start

### Prerequisites

- OpenShift 4.12+ cluster
- Cluster admin access
- `oc` CLI logged in
- Ansible 2.15+ with `kubernetes.core` collection

### 3-Minute Deployment

```bash
# 1. Clone the repository
git clone https://github.com/prakhar1985/rhpds.litemaas.git
cd rhpds.litemaas

# 2. Build and install collection
ansible-galaxy collection build --force
ansible-galaxy collection install rhpds-litemaas-*.tar.gz --force

# 3. Deploy (takes ~3 minutes)
ansible-playbook playbooks/deploy_litemaas.yml
```

### Access Your Deployment

After deployment completes, you'll see:

```
=========================================
LiteMaaS Deployment Complete!
=========================================
Frontend URL: https://litemaas-rhpds.apps.cluster-xxx.opentlc.com
LiteLLM Admin: https://litellm-rhpds.apps.cluster-xxx.opentlc.com

LiteLLM Admin Credentials:
  Username: admin
  Password: <auto-generated>
=========================================
```

**Admin Access:**
1. Open the LiteLLM Admin URL
2. Login with displayed credentials
3. Add AI models:
   - OpenShift AI local models (Granite, Llama, Mistral)
   - Cloud providers (DeepSeek, OpenAI, Anthropic, etc.)
4. Create virtual keys for users
5. Monitor usage and spending

**User Access:**
- Users receive virtual keys from admins
- Access models via OpenAI-compatible API
- Use any OpenAI SDK (Python, Node.js, etc.)
- See [docs/ADDING_MODELS.md](docs/ADDING_MODELS.md) for examples

## What Gets Deployed

All components deploy to the `rhpds` namespace:

| Component | Type | Description |
|-----------|------|-------------|
| **PostgreSQL** | StatefulSet | Persistent database for LiteLLM |
| **LiteLLM Gateway** | Deployment | AI model proxy with admin UI |
| **Routes** | Route | HTTPS access to admin portal |
| **Secrets** | Secret | Admin credentials and API keys |

**Note:** Frontend and Backend are optional and disabled by default. For admin-only deployments, only PostgreSQL and LiteLLM are deployed.

## Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `ocp4_workload_litemaas_namespace` | `rhpds` | Deployment namespace |
| `ocp4_workload_litemaas_version` | `0.1.2` | LiteMaaS version |
| `ocp4_workload_litemaas_cloud_provider` | auto-detect | Cloud provider |
| `ocp4_workload_litemaas_postgres_storage_class` | auto-detect | Storage class |
| `ocp4_workload_litemaas_postgres_storage_size` | `10Gi` | PVC size |

See `roles/ocp4_workload_litemaas/defaults/main.yml` for all variables.

## Examples

### Basic Deployment (Admin-Only)

```bash
ansible-playbook playbooks/deploy_litemaas.yml
```

This deploys:
- PostgreSQL database
- LiteLLM gateway with admin UI
- No frontend or backend (admin-only access)

### Enable Frontend/Backend (Optional)

If you want the web UI for end users:

```bash
ansible-playbook playbooks/deploy_litemaas.yml \
  -e ocp4_workload_litemaas_deploy_frontend=true \
  -e ocp4_workload_litemaas_deploy_backend=true \
  -e ocp4_workload_litemaas_oauth_enabled=true
```

### Custom Storage

```bash
ansible-playbook playbooks/deploy_litemaas.yml \
  -e ocp4_workload_litemaas_postgres_storage_size=50Gi
```

### Remove Deployment

```bash
ansible-playbook playbooks/deploy_litemaas.yml \
  -e ocp4_workload_litemaas_remove=true
```

## OpenShift AI Integration

Host local AI models using Red Hat OpenShift AI and make them available through LiteMaaS:

1. **Deploy models in OpenShift AI** (Granite, Llama, Mistral, etc.)
2. **Get inference endpoint URL**
3. **Add to LiteLLM** via Admin UI
4. **Create virtual keys** for users

See [docs/OPENSHIFT_AI_INTEGRATION.md](docs/OPENSHIFT_AI_INTEGRATION.md) for complete guide.

### Quick Example

```bash
# Get model endpoint from OpenShift AI
MODEL_URL=$(oc get inferenceservice granite-8b -n rhoai-models -o jsonpath='{.status.url}')

# Add to LiteLLM Admin UI:
#   Provider: OpenAI-Compatible
#   Model: granite-8b-instruct
#   API Base: ${MODEL_URL}/v1
```

## Prerequisites

- OpenShift 4.12+
- Ansible 2.15+
- `kubernetes.core` collection
- Cluster admin or project admin permissions

## Testing on RHDP Sandbox

```bash
# SSH to bastion
ssh lab-user@bastion.xxxxx.sandboxXXXX.opentlc.com

# Activate Python virtualenv
source /opt/virtualenvs/k8s/bin/activate

# Clone and deploy
git clone https://github.com/prakhar1985/rhpds.litemaas.git
cd rhpds.litemaas
ansible-playbook playbooks/deploy_litemaas.yml
```

## Status

ðŸš§ **Work in Progress** - Currently testing on AWS

## Author

**Prakhar Srivastava**
Manager, Technical Marketing - Red Hat Demo Platform
Red Hat

## License

MIT
