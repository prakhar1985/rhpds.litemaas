# Admin-Only Architecture

LiteMaaS has been simplified to an admin-only deployment model.

## Architecture Overview

```
┌─────────────────────────────────────────┐
│         LiteLLM Admin Portal            │
│  (https://litellm-rhpds.apps...)        │
│                                         │
│  Admin Functions:                       │
│  - Add AI models                        │
│  - Create virtual keys                  │
│  - Monitor usage/costs                  │
│  - Manage budgets                       │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│         LiteLLM Gateway                 │
│  (OpenAI-compatible API)                │
│                                         │
│  Routes requests to:                    │
│  - OpenShift AI models (local)          │
│  - DeepSeek API                         │
│  - OpenAI API                           │
│  - Anthropic API                        │
│  - etc.                                 │
└───────────────┬─────────────────────────┘
                │
                ▼
┌─────────────────────────────────────────┐
│         PostgreSQL Database             │
│                                         │
│  Stores:                                │
│  - Virtual keys                         │
│  - Usage metrics                        │
│  - Model configurations                 │
└─────────────────────────────────────────┘
```

## Components

### Deployed Components

| Component | Required | Description |
|-----------|----------|-------------|
| **PostgreSQL** | Yes | Stores virtual keys, usage data, model configs |
| **LiteLLM Gateway** | Yes | API gateway with admin UI |

### Removed Components

| Component | Status | Reason |
|-----------|--------|--------|
| **Frontend** | Optional (disabled) | Not needed for admin-only access |
| **Backend** | Optional (disabled) | Not needed for admin-only access |
| **OAuth Client** | Removed | No end-user authentication needed |

## Access Model

### Admin Access

**Who:** Platform administrators only

**How:** LiteLLM Admin UI
- URL: `https://litellm-rhpds.apps.cluster-xxx.opentlc.com`
- Login: admin / `<auto-generated-password>`

**Can Do:**
- Add/remove AI models
- Create virtual keys for users
- Set budget limits
- Monitor spending
- View usage analytics

### User Access

**Who:** End users (data scientists, developers, etc.)

**How:** API only (no web UI)
- Receive virtual key from admin
- Use OpenAI-compatible API
- Any OpenAI SDK works

**Can Do:**
- Make API requests to assigned models
- Check their own usage
- Subject to budget limits set by admin

## Workflow

### 1. Admin Sets Up Models

```bash
# Option A: Add OpenShift AI local model
# In LiteLLM Admin UI:
Provider: OpenAI-Compatible
Model: granite-8b-instruct
API Base: https://granite-8b-rhoai-models.apps.cluster.com/v1

# Option B: Add cloud model (DeepSeek)
Provider: Deepseek
Model: deepseek/deepseek-chat
API Key: sk-xxx
```

### 2. Admin Creates Virtual Key

```bash
# In LiteLLM Admin UI or via API:
curl https://litellm-rhpds.apps.cluster.com/key/generate \
  -H "Authorization: Bearer ${LITELLM_MASTER_KEY}" \
  -d '{
    "models": ["granite-8b-instruct", "deepseek-chat"],
    "max_budget": 100,
    "duration": "30d"
  }'

# Returns: sk-user-virtual-key-xxx
```

### 3. Admin Shares Key with User

Email or Slack:
```
Your LiteMaaS API key: sk-user-virtual-key-xxx
Base URL: https://litellm-rhpds.apps.cluster-xxx.opentlc.com
Models: granite-8b-instruct, deepseek-chat
Budget: $100/month
```

### 4. User Accesses Models

```python
import openai

client = openai.OpenAI(
    api_key="sk-user-virtual-key-xxx",
    base_url="https://litellm-rhpds.apps.cluster-xxx.opentlc.com"
)

response = client.chat.completions.create(
    model="granite-8b-instruct",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

## Configuration

### Default Configuration (Admin-Only)

```yaml
# In defaults/main.yml
ocp4_workload_litemaas_oauth_enabled: false
ocp4_workload_litemaas_deploy_frontend: false
ocp4_workload_litemaas_deploy_backend: false
ocp4_workload_litemaas_deploy_litellm: true
```

### Enable Frontend/Backend (Optional)

If you want to enable the web UI for end users:

```bash
ansible-playbook playbooks/deploy_litemaas.yml \
  -e ocp4_workload_litemaas_deploy_frontend=true \
  -e ocp4_workload_litemaas_deploy_backend=true \
  -e ocp4_workload_litemaas_oauth_enabled=true
```

## Benefits of Admin-Only Architecture

### ✅ Simplicity
- Fewer components to manage
- No OAuth configuration needed
- No frontend/backend to maintain

### ✅ Security
- Admin credentials only for admins
- Virtual keys with budget limits
- Easy to revoke user access
- No broad OAuth permissions needed

### ✅ Cost Control
- Set budget limits per key
- Track spending per user/team
- Monitor usage in real-time
- Alert on overspending

### ✅ Flexibility
- Users can use any OpenAI SDK
- Works with existing code
- No vendor lock-in
- Easy migration from OpenAI

### ✅ OpenShift AI Integration
- Host models locally
- No data leaves cluster
- Use GPUs efficiently
- Reduce cloud costs

## Deployment

### Fresh Deployment

```bash
# Clone repository
git clone https://github.com/prakhar1985/rhpds.litemaas.git
cd rhpds.litemaas

# Build and install collection
ansible-galaxy collection build --force
ansible-galaxy collection install rhpds-litemaas-*.tar.gz --force

# Deploy (admin-only by default)
ansible-playbook playbooks/deploy_litemaas.yml
```

### Update Existing Deployment

If you have an existing deployment with frontend/backend:

```bash
# Redeploy with admin-only mode
ansible-playbook playbooks/deploy_litemaas.yml \
  -e ocp4_workload_litemaas_deploy_frontend=false \
  -e ocp4_workload_litemaas_deploy_backend=false
```

This will scale down frontend/backend deployments while keeping LiteLLM and PostgreSQL running.

## Migration from OAuth-Based Access

If you previously used OpenShift OAuth:

### Before (OAuth Model)
1. User logs in with OpenShift credentials
2. User accesses web UI
3. User selects model from dropdown
4. Backend uses LiteLLM API

### After (Admin-Only Model)
1. Admin creates virtual key for user
2. Admin shares key with user
3. User uses API directly (no UI)
4. Direct access to LiteLLM

### Migration Steps

1. **Create virtual keys** for existing users:
   ```bash
   # For each user, create a key
   ./scripts/create-user-key.sh user@example.com \
     granite-8b-instruct,deepseek-chat 100 30d
   ```

2. **Share keys** with users via email/Slack

3. **Provide migration guide** to users:
   ```python
   # Old (frontend)
   # Login to https://litemaas-rhpds.apps.cluster.com
   # Click chat, select model, type message

   # New (API)
   import openai
   client = openai.OpenAI(
       api_key="sk-your-key",
       base_url="https://litellm-rhpds.apps.cluster.com"
   )
   response = client.chat.completions.create(
       model="granite-8b-instruct",
       messages=[{"role": "user", "content": "Your message"}]
   )
   ```

4. **Disable frontend** after migration period:
   ```bash
   oc scale deployment/litemaas-frontend --replicas=0 -n rhpds
   oc scale deployment/litemaas-backend --replicas=0 -n rhpds
   ```

## Monitoring

### Admin Dashboard

Access LiteLLM Admin to view:
- Active virtual keys
- Usage per key/user
- Cost breakdown by model
- Rate limit violations
- Error rates

### CLI Monitoring

```bash
# Get master key
MASTER_KEY=$(oc get secret litellm-secret -n rhpds -o jsonpath='{.data.LITELLM_MASTER_KEY}' | base64 -d)
LITELLM_URL=$(oc get route litellm -n rhpds -o jsonpath='{.spec.host}')

# List all keys
curl "https://${LITELLM_URL}/key/info" \
  -H "Authorization: Bearer ${MASTER_KEY}"

# Check specific key
curl "https://${LITELLM_URL}/key/info?key=sk-user-key" \
  -H "Authorization: Bearer ${MASTER_KEY}"

# View spending
curl "https://${LITELLM_URL}/global/spend" \
  -H "Authorization: Bearer ${MASTER_KEY}"
```

## Troubleshooting

### Can't Access Admin UI

```bash
# Check LiteLLM pod is running
oc get pods -n rhpds -l app=litellm

# Check route
oc get route litellm -n rhpds

# Get admin credentials
oc get secret litellm-secret -n rhpds -o jsonpath='{.data.UI_PASSWORD}' | base64 -d
```

### Virtual Key Not Working

```bash
# Check key exists
curl "https://${LITELLM_URL}/key/info?key=sk-xxx" \
  -H "Authorization: Bearer ${MASTER_KEY}"

# Check key budget
# If budget is 0 or expired, key won't work
```

### Model Not Accessible

```bash
# Check model is added in LiteLLM
curl "https://${LITELLM_URL}/models" \
  -H "Authorization: Bearer ${MASTER_KEY}"

# Test model directly
curl "https://${LITELLM_URL}/chat/completions" \
  -H "Authorization: Bearer ${MASTER_KEY}" \
  -d '{"model": "granite-8b-instruct", "messages": [{"role": "user", "content": "test"}]}'
```

## Documentation

- [Adding Models](docs/ADDING_MODELS.md) - How to add AI models
- [OpenShift AI Integration](docs/OPENSHIFT_AI_INTEGRATION.md) - Host local models
- [README](README.md) - Quick start guide

## Support

For issues or questions:
- GitHub Issues: https://github.com/prakhar1985/rhpds.litemaas/issues
- RHDP Team: Prakhar Srivastava
